{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  529384\n",
      "10 first rows:  [\n",
      "  [\n",
      "    \"000000.pn01.edugroup.at\",\n",
      "    \"000000.tpn01.edugroup.at\",\n",
      "    \"00000.cz\",\n",
      "    \"0:0:0:0:0:FFFF:B76E:5A27\",\n",
      "    \"00000fs3085d.han2.savba.sk\",\n",
      "    \"0000100b00e9.han2.savba.sk\",\n",
      "    \"0000100b01bd.han2.savba.sk\",\n",
      "    \"0000100m0030.han2.savba.sk\",\n",
      "    \"0000100q012c.han2.savba.sk\",\n",
      "    \"0000100q0296.han2.savba.sk\"\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import re\n",
    "\n",
    "\n",
    "parquet_file = pq.read_table('CESNET_domains.parquet')\n",
    "\n",
    "#print number of rows\n",
    "print(\"Number of rows: \", parquet_file.num_rows)\n",
    "\n",
    "#save it to txt \n",
    "with open('CESNET_domains.txt', 'w') as f:\n",
    "    for i in range(0,parquet_file.num_rows):\n",
    "        #print(parquet_file.column(0)[i])\n",
    "        f.write(str(parquet_file.column(0)[i]))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "#print 10 first rows\n",
    "print(\"10 first rows: \", parquet_file.column(0)[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/survivecz/.local/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'pyarrow.lib.ChunkedArray' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/petrp/desktop/FETA/dr-playground/CESNET/Domain_sampling_parquet.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/CESNET/Domain_sampling_parquet.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m ddf \u001b[39m=\u001b[39m pq\u001b[39m.\u001b[39mread_table(\u001b[39m'\u001b[39m\u001b[39mCESNET_domains.parquet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/CESNET/Domain_sampling_parquet.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Apply the extract_domain function to the 'DOMAIN' column.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/CESNET/Domain_sampling_parquet.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m ddf[\u001b[39m'\u001b[39m\u001b[39mextracted\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ddf[\u001b[39m'\u001b[39;49m\u001b[39mDOMAIN\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmap(extract_domain, meta\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mextracted\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/CESNET/Domain_sampling_parquet.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Filter rows where the domain is invalid or could not be extracted.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/CESNET/Domain_sampling_parquet.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m ddf \u001b[39m=\u001b[39m ddf[ddf[\u001b[39m'\u001b[39m\u001b[39mextracted\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'pyarrow.lib.ChunkedArray' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import tldextract\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "cutoff = 50\n",
    "def extract_domain(x):\n",
    "    ext = tldextract.extract(x)\n",
    "    return ext.registered_domain if ext.registered_domain else x\n",
    "\n",
    "# Read the Parquet file using Dask DataFrame.\n",
    "ddf = pq.read_table('CESNET_domains.parquet')\n",
    "\n",
    "# Apply the extract_domain function to the 'DOMAIN' column.\n",
    "ddf['extracted'] = ddf['DOMAIN'].map(extract_domain, meta=('extracted', 'object'))\n",
    "\n",
    "# Filter rows where the domain is invalid or could not be extracted.\n",
    "ddf = ddf[ddf['extracted'] != '']\n",
    "\n",
    "# Since Dask operations are lazy, up to this point, no computations have been performed.\n",
    "# Now, let's perform a streaming computation to get the top domains by suffix.\n",
    "top_domains_by_suffix = ddf.groupby('extracted').size().nlargest(cutoff).compute()\n",
    "\n",
    "# Get the list of top domains.\n",
    "top_domains_list = top_domains_by_suffix.index.tolist()\n",
    "\n",
    "# Now filter the original DDF to only include the top domains.\n",
    "filtered_ddf = ddf[ddf['extracted'].isin(top_domains_list)]\n",
    "\n",
    "# Perform a random sample of the filtered DDF.\n",
    "sampled_ddf = filtered_ddf.sample(frac=(600000 / len(filtered_ddf)), random_state=42)\n",
    "\n",
    "# Write the sampled data directly to a text file, one domain name per line.\n",
    "# This operation is lazy and will be computed only when triggered.\n",
    "fraction_to_sample = 600_000 / len(filtered_ddf)\n",
    "\n",
    "# Perform a random sample of the filtered DDF.\n",
    "# The `random_state` ensures that the sample is reproducible.\n",
    "sampled_ddf = filtered_ddf.sample(frac=fraction_to_sample, random_state=42)\n",
    "\n",
    "# This writes the sampled data directly to a text file, one domain name per line.\n",
    "# The asterisk (*) in the filename will be replaced with numbers to denote different parts if needed.\n",
    "# We ensure that each partition writes to its own file to avoid memory issues.\n",
    "paths = sampled_ddf['extracted'].to_textfiles('domains_sampled_*.txt', index=False)\n",
    "\n",
    "\n",
    "# import os\n",
    "# os.system(\"cat domains_sampled_*.txt > combined_domains.txt\")\n",
    "\n",
    "# # After this step, you can delete the part files if you want to keep only the combined file.\n",
    "# for path in paths:\n",
    "#     os.remove(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
