{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be able to run your async code in the notebook\n",
    "import nest_asyncio\n",
    "import sys\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "import subprocess\n",
    "from typing import List, Tuple, Optional\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm  # tqdm.notebook for Jupyter notebook\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfMerger\n",
    "import math\n",
    "import requests\n",
    "import datetime\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from requests.exceptions import RequestException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'benign'  # You can change this to 'benign' to read from the benign dataset\n",
    "input_mode = 'txt'  # You can change this to 'txt'\n",
    "# Maximum of api calls for VirusTotal, current academic api is 20k per day\n",
    "batch_size = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DomainAnalyzer\n",
    "**Objective**: Define the `DomainAnalyzer` class that will handle domain analysis tasks.\n",
    "\n",
    "- **Functions Included**:\n",
    "    - `__init__`: Initializes the `DomainAnalyzer` with a VirusTotal API key loaded from an environment variable.\n",
    "    - `__enter__` and `__exit__`: Context management methods to handle the setup and cleanup of the client.\n",
    "    - `initialize_client`: Load API key and initialize the vt.Client.\n",
    "    - `check_domain`: Fetch information for a specific domain.\n",
    "    - `get_verdict`: Determine the verdict of the analysis based on the domain's analysis stats.\n",
    "    - `is_domain_live`: Check if a domain is live by calling a bash script.\n",
    "    - `extract_domain_data`: Extract necessary data from the domain result.\n",
    "    - `load_previous_data`: Load previously processed domain data from a CSV file.\n",
    "    - `save_data`: Save the DataFrame containing domain data to a CSV file.\n",
    "    - `generate_report`: Generate a report based on the DataFrame and save it as a PDF.\n",
    "    - `process_selected_domains`: Process the domains based on the mode ('malign' or 'benign') in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.api_key = self._load_api_key()\n",
    "        self.headers = self._create_headers()\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_api_key():\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv('VT_API_KEY')\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"API key is not set. Please set the VT_API_KEY environment variable.\")\n",
    "        return api_key\n",
    "\n",
    "    def _create_headers(self):\n",
    "        return {\"x-apikey\": self.api_key, \"Accept\": \"application/json\"}\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        pass\n",
    "    \n",
    "    def check_domain(self, domain: str) -> Optional[dict]:\n",
    "        url = f\"https://www.virustotal.com/api/v3/domains/{domain}\"\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        elif response.status_code == 429:\n",
    "            print(f\"Quota exceeded when attempting to fetch information for domain {domain}.\")\n",
    "            return \"Quota Exceeded\"\n",
    "        else:\n",
    "            print(f\"Error: Unable to fetch information for domain {domain}. {response.text}\")\n",
    "            return None\n",
    "\n",
    "    def _determine_verdict(self, analysis_stats: dict) -> str:\n",
    "        return \"Malign\" if analysis_stats.get('malicious', 0) > 0 or analysis_stats.get('suspicious', 0) > 1 else \"Benign\" \n",
    "        \n",
    "    def _is_domain_live(self, domain: str) -> str:\n",
    "        try:\n",
    "            result = subprocess.run(['./livetest.sh', domain], capture_output=True, text=True)\n",
    "            return \"Alive\" if result.stdout.strip() == '1' else \"Dead\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error: Unable to check if domain {domain} is live. {e}\")\n",
    "            return \"Unknown\"\n",
    "        \n",
    "    def _format_timestamp(self, timestamp):\n",
    "        return datetime.datetime.utcfromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    def extract_domain_data(self, domain: str, result: dict) -> Optional[Tuple]:\n",
    "        try:\n",
    "            attributes = result['data']['attributes']\n",
    "            analysis_stats = attributes['last_analysis_stats']\n",
    "            verdict = self._determine_verdict(analysis_stats)\n",
    "            detection_ratio = f\"{analysis_stats['malicious']}/{analysis_stats['malicious'] + analysis_stats['harmless']}\"\n",
    "\n",
    "            last_analysis_date = attributes.get('last_analysis_date', attributes.get('last_submission_date', 0))\n",
    "            formatted_timestamp = self._format_timestamp(last_analysis_date) if last_analysis_date else 'N/A'\n",
    "\n",
    "            domain_status = self._is_domain_live(domain)\n",
    "            return (domain, verdict, detection_ratio, formatted_timestamp, analysis_stats.get('harmless', 0), analysis_stats.get('malicious', 0), analysis_stats.get('suspicious', 0), domain_status)\n",
    "        except KeyError:\n",
    "            print(f\"Error: Could not extract analysis stats for domain {domain}\")\n",
    "            return None\n",
    "\n",
    "    def load_previous_data(self, mode: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load previously processed domain data from a CSV file or text file.\n",
    "        \"\"\"\n",
    "\n",
    "        previous_data_filename = f'previous_data_{mode}.csv'\n",
    "        if os.path.exists(previous_data_filename):\n",
    "            return pd.read_csv(previous_data_filename)\n",
    "        else:\n",
    "            columns = [\"Domain\", \"Verdict\", \"Detection Ratio\", \"Detection Timestamp\", \"Harmless\", \"Malicious\", \"Suspicious\", \"Live Status\"]\n",
    "            return pd.DataFrame(columns=columns)\n",
    "\n",
    "    def save_data(self, df: pd.DataFrame, mode) -> None:\n",
    "        \"\"\"\n",
    "        Save the DataFrame containing domain data to a CSV file or text file.\n",
    "        \"\"\"\n",
    "\n",
    "        df.to_csv(f'previous_data_{mode}.csv', index=False)\n",
    "\n",
    "    def save_checkpoint(self, data, processed_domains, mode, total_processed):\n",
    "        columns = [\"Domain\", \"Verdict\", \"Detection Ratio\", \"Detection Timestamp\", \"Harmless\", \"Malicious\", \"Suspicious\", \"Live Status\"]\n",
    "        new_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "        # Load the previous data\n",
    "        old_df = self.load_previous_data(mode)\n",
    "        \n",
    "        # Merge the old and new data, removing duplicates\n",
    "        merged_df = pd.concat([old_df, new_df]).drop_duplicates(subset=['Domain']).reset_index(drop=True)\n",
    "        self.save_data(merged_df, mode)\n",
    "\n",
    "        # Overwrite the processed domains file with the updated list\n",
    "        processed_domains_file = f\"processed_domains_{mode}.txt\"\n",
    "        with open(processed_domains_file, 'w') as file:\n",
    "            file.write('\\n'.join(processed_domains))\n",
    "        print(f\"Checkpoint saved to previous_data_{mode}.csv and processed_domains_{mode}.txt\")\n",
    "\n",
    "    def generate_report(self, df: pd.DataFrame, output_filename: str, rows_per_page: int = 500) -> None:\n",
    "        \"\"\"\n",
    "        Generate a report based on the DataFrame and save it as a PDF, including a summary at the end.\n",
    "        \"\"\"\n",
    "        num_pages = math.ceil(len(df) / rows_per_page)\n",
    "\n",
    "        benign_count = len(df[df['Verdict'] == 'Benign'])\n",
    "        malign_count = len(df[df['Verdict'] == 'Malign'])\n",
    "        total_count = len(df)\n",
    "\n",
    "        with PdfPages(output_filename) as pdf_pages:\n",
    "            for page in range(num_pages):\n",
    "                start_row = page * rows_per_page\n",
    "                end_row = start_row + rows_per_page\n",
    "                page_df = df[start_row:end_row]\n",
    "\n",
    "                # If it's the last page, add the summary rows\n",
    "                if page == num_pages - 1:\n",
    "                    page_df = page_df.fillna('-')\n",
    "                    summary_df = pd.DataFrame({\n",
    "                        \"Domain\": [\"\", \"\"],\n",
    "                        \"Verdict\": [\"Benign count\", \"Malign count\"],\n",
    "                        \"Detection Ratio\": [f\"{benign_count}/{total_count}\", f\"{malign_count}/{total_count}\"],\n",
    "                        # Other columns can be filled with appropriate data or left empty\n",
    "                    }).reindex(columns=page_df.columns).fillna('-')\n",
    "\n",
    "                    page_df = pd.concat([page_df, summary_df], ignore_index=True)\n",
    "\n",
    "                fig_height = max(len(page_df) * 0.01, 4.8)  # Ensure a minimum height\n",
    "                fig, ax = plt.subplots(figsize=(11, fig_height))\n",
    "                \n",
    "                ax.axis('off')  # Hide axes\n",
    "                plt.tight_layout(pad=0.2)\n",
    "\n",
    "                colWidths = [\n",
    "                    max(page_df[\"Domain\"].apply(lambda x: len(x) if x is not None else 0).max() * 0.25, 0.1) * 0.02 if column == \"Domain\" \n",
    "                    else 0.15 if column == \"Detection Timestamp\" \n",
    "                    else 0.1 for column in page_df.columns\n",
    "                ]\n",
    "\n",
    "                tab = pd.plotting.table(ax, page_df, loc='upper center', colWidths=colWidths, cellLoc='center', rowLoc='center')\n",
    "                tab.auto_set_font_size(False)\n",
    "                tab.set_fontsize(8)\n",
    "                tab.scale(1.2, 1.2)\n",
    "\n",
    "                for key, cell in tab.get_celld().items():\n",
    "                    if key[0] == 0 or key[1] == -1:\n",
    "                        cell.get_text().set_weight('bold')\n",
    "                    if 'Verdict' in page_df.columns:\n",
    "                        if cell.get_text().get_text() == 'Malign':\n",
    "                            cell.set_text_props(color='red')\n",
    "                        elif cell.get_text().get_text() == 'Benign':\n",
    "                            cell.set_text_props(color='green')\n",
    "                    if 'Live Status' in page_df.columns:\n",
    "                        if cell.get_text().get_text() == 'Live':\n",
    "                            cell.set_text_props(color='green')\n",
    "                        elif cell.get_text().get_text() == 'Dead':\n",
    "                            cell.set_text_props(color='red')\n",
    "                    if key[1] == -1:\n",
    "                        cell.set_visible(False)\n",
    "                    if page == num_pages - 1 and key[0] >= len(page_df) - 1:  # This line is changed\n",
    "                        cell.set_text_props(weight='bold')\n",
    "                        cell.get_text().set_color('black')\n",
    "                        cell.set_facecolor('lightgrey')\n",
    "\n",
    "                pdf_pages.savefig(fig, bbox_inches='tight')\n",
    "                plt.close(fig)\n",
    "\n",
    "    def process_selected_domains(self, input_mode: str, mode: str, batch_size) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Process the domains based on the mode ('malign' or 'benign') in batches.\n",
    "        \"\"\"\n",
    "        if input_mode not in ['parquet', 'txt']:\n",
    "            print(f\"Invalid input mode '{input_mode}'. Please use 'parquet' or 'txt'.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        paths = {\n",
    "            'parquet': {\n",
    "                'malign': '../floor/malware.parquet',\n",
    "                'benign': '../floor/benign_cesnet_union_2307.parquet'\n",
    "            },\n",
    "            'txt': {\n",
    "                'malign': '',\n",
    "                'benign': '../cesnet/CESNET/CESNET_domains_530K.txt',\n",
    "            }\n",
    "        }\n",
    "        # Read the selected Parquet file or text file and get the domain names\n",
    "        if input_mode == 'parquet':\n",
    "            table = pq.read_table(paths[input_mode][mode])\n",
    "            domain_names = table.column('domain_name').to_pandas()\n",
    "        else:  # input_mode == 'txt'\n",
    "            #open the file and read the lines\n",
    "            with open(paths[input_mode][mode], 'r') as file:\n",
    "                domain_names = file.read().splitlines()\n",
    "\n",
    "        # Load the processed domains\n",
    "        processed_domains_file = f\"processed_domains_{mode}.txt\"\n",
    "\n",
    "        \n",
    "        if os.path.exists(processed_domains_file):\n",
    "            with open(processed_domains_file, 'r') as file:\n",
    "                processed_domains = file.read().splitlines()\n",
    "        else:\n",
    "            processed_domains = []\n",
    "\n",
    "        data = []\n",
    "        processed_in_this_run = 0\n",
    "        total_processed = len(processed_domains)\n",
    "        \n",
    "        progress_bar = tqdm(total=len(domain_names), desc='Processing domains', unit='domain')\n",
    "        for domain in domain_names:\n",
    "            progress_bar.update(1)\n",
    "            if domain not in processed_domains:\n",
    "                try:\n",
    "                    result = self.check_domain(domain)\n",
    "                    if result == \"Quota Exceeded\":\n",
    "                        # Quota exceeded, generate report and exit\n",
    "                        print(\"Quota is exceeded, generating report...\")\n",
    "                        df = self.load_previous_data(mode)\n",
    "                        df.sort_values(by=['Verdict', 'Live Status'], ascending=[False, False], inplace=True)\n",
    "                        df.dropna(inplace=True)\n",
    "                        progress_bar.close()\n",
    "                        return df\n",
    "                    elif result:\n",
    "                        # Extract data if domain check was successful\n",
    "                        data.append(self.extract_domain_data(domain, result))\n",
    "                        processed_domains.append(domain)  # Assuming processed_domains is a set\n",
    "                        processed_in_this_run += 1\n",
    "                        total_processed += 1\n",
    "                        \n",
    "                        # Checkpoint save logic remains unchanged\n",
    "                        if total_processed % 1000 == 0:\n",
    "                            self.save_checkpoint(data, processed_domains, mode, total_processed)\n",
    "                except Exception as e:\n",
    "                    print(f\"Unexpected error occurred: {e}\")\n",
    "                if processed_in_this_run >= batch_size:\n",
    "                    break\n",
    "        progress_bar.close()\n",
    "\n",
    "        self.save_checkpoint(data, processed_domains, mode, total_processed)\n",
    "        columns = [\"Domain\", \"Verdict\", \"Detection Ratio\", \"Detection Timestamp\", \"Harmless\", \"Malicious\", \"Suspicious\", \"Live Status\"]\n",
    "        \n",
    "        # Create a DataFrame from the newly processed data\n",
    "        new_df = pd.DataFrame(data, columns=columns)\n",
    "        old_df = self.load_previous_data(mode)\n",
    "\n",
    "        if old_df.empty:\n",
    "            merged_df = new_df\n",
    "        elif new_df.empty:\n",
    "            merged_df = old_df\n",
    "        else:\n",
    "            merged_df = pd.concat([old_df, new_df]).drop_duplicates(subset=['Domain']).reset_index(drop=True)\n",
    "        \n",
    "        merged_df.sort_values(by=['Verdict', 'Live Status'], ascending=[False, False], inplace=True)\n",
    "        merged_df.dropna(inplace=True)\n",
    "        # Save the merged data\n",
    "        self.save_data(merged_df, mode)\n",
    "        #print how many domains were processed in total, also include percentages\n",
    "        print(f\"Total number of domains processed: {len(merged_df)} out of {len(domain_names)} ({len(merged_df)/len(domain_names)*100:.2f}%)\")\n",
    "        return merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: Utilize the `DomainAnalyzer` class to process and analyze domains.\n",
    "\n",
    "- **Steps**:\n",
    "    1. Instantiate the `DomainAnalyzer` class.\n",
    "    2. Use the `process_selected_domains` method to process domains based on the specified mode and batch size.\n",
    "    3. If domains are processed successfully, generate and save a report using the `generate_report` method.\n",
    "\n",
    "**Note**: Ensure that you have the necessary files, API keys, and configurations before running this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de5144db12b4f838d9df445a070c5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing domains:   0%|          | 0/529385 [00:00<?, ?domain/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to fetch information for domain 0:0:0:0:0:FFFF:B76E:5A27. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0:0:0:0:0:FFFF:B76E:5A27\\\" is not a valid domain pattern\",\n",
      "        \"code\": \"InvalidArgumentError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 00000fs3085d.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"00000fs3085d.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000100b00e9.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000100b00e9.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000100b01bd.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000100b01bd.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000100m0030.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000100m0030.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000100q012c.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000100q012c.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000100q0296.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000100q0296.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000101m0051.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000101m0051.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n0120.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n0120.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n0175.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n0175.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n0177.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n0177.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n01d2.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n01d2.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n025e.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n025e.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n0293.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n0293.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n02b6.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n02b6.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n02c2.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n02c2.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n02c4.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n02c4.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n02d5.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n02d5.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n030d.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n030d.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n030e.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n030e.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n0319.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n0319.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n0347.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n0347.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n0364.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n0364.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n036c.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n036c.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n03d3.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n03d3.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 0000102n0434.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"0000102n0434.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 000010560066.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"000010560066.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n",
      "Error: Unable to fetch information for domain 000010560091.han2.savba.sk. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Domain \\\"000010560091.han2.savba.sk\\\" not found\",\n",
      "        \"code\": \"NotFoundError\"\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Example usage in a Jupyter notebook cell:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m DomainAnalyzer() \u001b[39mas\u001b[39;00m analyzer:  \u001b[39m# Using the analyzer as a context manager\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     df \u001b[39m=\u001b[39m analyzer\u001b[39m.\u001b[39;49mprocess_selected_domains(input_mode, mode, batch_size)  \u001b[39m# This should generate your DataFrame df\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m df \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m df\u001b[39m.\u001b[39mempty:  \u001b[39m# Ensure that df is not empty or None\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         analyzer\u001b[39m.\u001b[39mgenerate_report(df, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m_VT_check.pdf\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# This will use the DataFrame df\u001b[39;00m\n",
      "\u001b[1;32m/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=212'>213</a>\u001b[0m \u001b[39mif\u001b[39;00m domain \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_domains:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=213'>214</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=214'>215</a>\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_domain(domain)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=215'>216</a>\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mQuota Exceeded\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=216'>217</a>\u001b[0m             \u001b[39m# Quota exceeded, generate report and exit\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=217'>218</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mQuota is exceeded, generating report...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_domain\u001b[39m(\u001b[39mself\u001b[39m, domain: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39mdict\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://www.virustotal.com/api/v3/domains/\u001b[39m\u001b[39m{\u001b[39;00mdomain\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/c/Users/petrp/desktop/FETA/dr-playground/VT/vt_checker.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/urllib3/connection.py:454\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    453\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1379\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1312\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage in a Jupyter notebook cell:\n",
    "with DomainAnalyzer() as analyzer:  # Using the analyzer as a context manager\n",
    "    df = analyzer.process_selected_domains(input_mode, mode, batch_size)  # This should generate your DataFrame df\n",
    "    if df is not None and not df.empty:  # Ensure that df is not empty or None\n",
    "        analyzer.generate_report(df, f'{mode}_VT_check.pdf')  # This will use the DataFrame df\n",
    "        print(f'Report saved as {mode}_VT_check.pdf')\n",
    "    else:\n",
    "        print(f\"No domains processed for mode '{mode}'. No report generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
